{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "intro_to_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4RpK9pawQzP"
      },
      "source": [
        "# Intro to PyTorch: Training your first neural network using PyTorch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SgTVT3HagGZ"
      },
      "source": [
        "## Blog Post Code\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcrOk6pURp50"
      },
      "source": [
        "### Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJaCNlDDRz6d"
      },
      "source": [
        "# import the necessary packages\n",
        "from collections import OrderedDict\n",
        "from torch.optim import SGD\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_blobs\n",
        "import torch.nn as nn\n",
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5m6PVgO7DCf"
      },
      "source": [
        "### Implementing our neural network with PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24udECNc7D3C"
      },
      "source": [
        "# import the necessary packages\n",
        "from collections import OrderedDict\n",
        "import torch.nn as nn\n",
        "\n",
        "def get_training_model(inFeatures=4, hiddenDim=8, nbClasses=3):\n",
        "\t# construct a shallow, sequential neural network\n",
        "\tmlpModel = nn.Sequential(OrderedDict([\n",
        "\t\t(\"hidden_layer_1\", nn.Linear(inFeatures, hiddenDim)),\n",
        "\t\t(\"activation_1\", nn.ReLU()),\n",
        "\t\t(\"output_layer\", nn.Linear(hiddenDim, nbClasses))\n",
        "\t]))\n",
        "\n",
        "\t# return the sequential model\n",
        "\treturn mlpModel"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jppw5-Bd56H-"
      },
      "source": [
        "### Creating our PyTorch training script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5hKyclI7QYd"
      },
      "source": [
        "def next_batch(inputs, targets, batchSize):\n",
        "\t# loop over the dataset\n",
        "\tfor i in range(0, inputs.shape[0], batchSize):\n",
        "\t\t# yield a tuple of the current batched data and labels\n",
        "\t\tyield (inputs[i:i + batchSize], targets[i:i + batchSize])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okM7Bpyeq8Kc",
        "outputId": "2beb783d-1070-486d-fe0a-d57872d803b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# specify our batch size, number of epochs, and learning rate\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10\n",
        "LR = 1e-2\n",
        "\n",
        "# determine the device we will be using for training\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"[INFO] training using {}...\".format(DEVICE))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] training using cpu...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d652MZk7TZY",
        "outputId": "c5b4b21b-1652-4e1f-df57-0ec7a2dc5c11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# generate a 3-class classification problem with 1000 data points,\n",
        "# where each data point is a 4D feature vector\n",
        "print(\"[INFO] preparing data...\")\n",
        "(X, y) = make_blobs(n_samples=1000, n_features=4, centers=3,\n",
        "\tcluster_std=2.5, random_state=95)\n",
        "\n",
        "# create training and testing splits, and convert them to PyTorch\n",
        "# tensors\n",
        "(trainX, testX, trainY, testY) = train_test_split(X, y,\n",
        "\ttest_size=0.15, random_state=95)\n",
        "trainX = torch.from_numpy(trainX).float()\n",
        "testX = torch.from_numpy(testX).float()\n",
        "trainY = torch.from_numpy(trainY).float()\n",
        "testY = torch.from_numpy(testY).float()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] preparing data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIjE_Eb3dffo",
        "outputId": "e790322e-1dfd-48b6-e68f-7371f79c5004",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3.5596, 4.0420, 5.9104, 0.4815])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB-PgkG17VYv",
        "outputId": "12925630-4d25-4588-c7ef-fdfd2c7d940f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# initialize our model and display its architecture\n",
        "mlp = get_training_model().to(DEVICE)\n",
        "print(mlp)\n",
        "\n",
        "# initialize optimizer and loss function\n",
        "opt = SGD(mlp.parameters(), lr=LR)\n",
        "lossFunc = nn.CrossEntropyLoss()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (hidden_layer_1): Linear(in_features=4, out_features=8, bias=True)\n",
            "  (activation_1): ReLU()\n",
            "  (output_layer): Linear(in_features=8, out_features=3, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F00FGW0J7XES",
        "outputId": "ccf041cd-5ef6-475e-cca7-cc1e93e8ee40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# loop through the epochs\n",
        "for epoch in range(0, EPOCHS):\n",
        "\t# initialize tracker variables and set our model to trainable\n",
        "\tprint(\"[INFO] epoch: {}...\".format(epoch + 1))\n",
        "\ttrainLoss = 0\n",
        "\ttrainAcc = 0\n",
        "\tsamples = 0\n",
        "\tmlp.train()\n",
        "\n",
        "\t# loop over the current batch of data\n",
        "\tfor (batchX, batchY) in next_batch(trainX, trainY, BATCH_SIZE):\n",
        "\t\t# flash data to the current device, run it through our\n",
        "\t\t# model, and calculate loss\n",
        "\t\t(batchX, batchY) = (batchX.to(DEVICE), batchY.to(DEVICE))\n",
        "\t\tpredictions = mlp(batchX)\n",
        "\t\tloss = lossFunc(predictions, batchY.long())\n",
        "\n",
        "\t\t# zero the gradients accumulated from the previous steps,\n",
        "\t\t# perform backpropagation, and update model parameters\n",
        "\t\topt.zero_grad()\n",
        "\t\tloss.backward()\n",
        "\t\topt.step()\n",
        "\n",
        "\t\t# update training loss, accuracy, and the number of samples\n",
        "\t\t# visited\n",
        "\t\ttrainLoss += loss.item() * batchY.size(0)\n",
        "\t\ttrainAcc += (predictions.max(1)[1] == batchY).sum().item()\n",
        "\t\tsamples += batchY.size(0)\n",
        "\n",
        "\t# display model progress on the current training batch\n",
        "\ttrainTemplate = \"epoch: {} train loss: {:.3f} train accuracy: {:.3f}\"\n",
        "\tprint(trainTemplate.format(epoch + 1, (trainLoss / samples),\n",
        "\t\t(trainAcc / samples)))\n",
        "\n",
        "\t# initialize tracker variables for testing, then set our model to\n",
        "\t# evaluation mode\n",
        "\ttestLoss = 0\n",
        "\ttestAcc = 0\n",
        "\tsamples = 0\n",
        "\tmlp.eval()\n",
        "\n",
        "\t# initialize a no-gradient context\n",
        "\twith torch.no_grad():\n",
        "\t\t# loop over the current batch of test data\n",
        "\t\tfor (batchX, batchY) in next_batch(testX, testY, BATCH_SIZE):\n",
        "\t\t\t# flash the data to the current device\n",
        "\t\t\t(batchX, batchY) = (batchX.to(DEVICE), batchY.to(DEVICE))\n",
        "\n",
        "\t\t\t# run data through our model and calculate loss\n",
        "\t\t\tpredictions = mlp(batchX)\n",
        "\t\t\tloss = lossFunc(predictions, batchY.long())\n",
        "\n",
        "\t\t\t# update test loss, accuracy, and the number of\n",
        "\t\t\t# samples visited\n",
        "\t\t\ttestLoss += loss.item() * batchY.size(0)\n",
        "\t\t\ttestAcc += (predictions.max(1)[1] == batchY).sum().item()\n",
        "\t\t\tsamples += batchY.size(0)\n",
        "\n",
        "\t\t# display model progress on the current test batch\n",
        "\t\ttestTemplate = \"epoch: {} test loss: {:.3f} test accuracy: {:.3f}\"\n",
        "\t\tprint(testTemplate.format(epoch + 1, (testLoss / samples),\n",
        "\t\t\t(testAcc / samples)))\n",
        "\t\tprint(\"\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] epoch: 1...\n",
            "epoch: 1 train loss: 0.692 train accuracy: 0.694\n",
            "epoch: 1 test loss: 0.646 test accuracy: 0.747\n",
            "\n",
            "[INFO] epoch: 2...\n",
            "epoch: 2 train loss: 0.601 train accuracy: 0.740\n",
            "epoch: 2 test loss: 0.560 test accuracy: 0.793\n",
            "\n",
            "[INFO] epoch: 3...\n",
            "epoch: 3 train loss: 0.526 train accuracy: 0.776\n",
            "epoch: 3 test loss: 0.479 test accuracy: 0.820\n",
            "\n",
            "[INFO] epoch: 4...\n",
            "epoch: 4 train loss: 0.455 train accuracy: 0.812\n",
            "epoch: 4 test loss: 0.407 test accuracy: 0.847\n",
            "\n",
            "[INFO] epoch: 5...\n",
            "epoch: 5 train loss: 0.390 train accuracy: 0.848\n",
            "epoch: 5 test loss: 0.346 test accuracy: 0.867\n",
            "\n",
            "[INFO] epoch: 6...\n",
            "epoch: 6 train loss: 0.331 train accuracy: 0.881\n",
            "epoch: 6 test loss: 0.293 test accuracy: 0.887\n",
            "\n",
            "[INFO] epoch: 7...\n",
            "epoch: 7 train loss: 0.281 train accuracy: 0.902\n",
            "epoch: 7 test loss: 0.247 test accuracy: 0.913\n",
            "\n",
            "[INFO] epoch: 8...\n",
            "epoch: 8 train loss: 0.239 train accuracy: 0.918\n",
            "epoch: 8 test loss: 0.209 test accuracy: 0.927\n",
            "\n",
            "[INFO] epoch: 9...\n",
            "epoch: 9 train loss: 0.205 train accuracy: 0.936\n",
            "epoch: 9 test loss: 0.177 test accuracy: 0.953\n",
            "\n",
            "[INFO] epoch: 10...\n",
            "epoch: 10 train loss: 0.177 train accuracy: 0.946\n",
            "epoch: 10 test loss: 0.153 test accuracy: 0.967\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}